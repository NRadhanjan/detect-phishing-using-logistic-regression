{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Lzp9LfFKy7v"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('All.csv')"
      ],
      "metadata": {
        "id": "GbKWoTw8Lncr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())"
      ],
      "metadata": {
        "id": "ev1u7gLxLtC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.shape)"
      ],
      "metadata": {
        "id": "CLeof532MY01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = (df['URL_Type_obf_Type'] == 'benign').sum()\n",
        "print(count)\n",
        "count = (df['URL_Type_obf_Type'] == 'phishing').sum()\n",
        "print(count)"
      ],
      "metadata": {
        "id": "Z1JNa6VJMwda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "desired_classes=['benign','phishing']\n",
        "df_flitered = df[df['URL_Type_obf_Type'].isin(desired_classes)].copy()\n",
        "print(df.shape)\n",
        "print(df_flitered.shape)"
      ],
      "metadata": {
        "id": "Ko5Vg3IINC1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = (df_flitered['URL_Type_obf_Type'] == 'benign').sum()\n",
        "print(count)\n",
        "count = (df_flitered['URL_Type_obf_Type'] == 'phishing').sum()\n",
        "print(count)"
      ],
      "metadata": {
        "id": "4ORwt8xVNZuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_mapping = {'benign':0 , 'phishing':1}\n",
        "df_flitered['target']= df_flitered['URL_Type_obf_Type'].map(label_mapping)\n",
        "df_flitered = df_flitered.drop(columns=['URL_Type_obf_Type'])\n",
        "print(df_flitered['target'].value_counts())"
      ],
      "metadata": {
        "id": "pZbLySP4NoMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_flitered.head()"
      ],
      "metadata": {
        "id": "itmSYg9JOFLc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_flitered.isnull().sum().sum())\n",
        "df_flitered = df_flitered.fillna(0)\n",
        "print(df_flitered.isnull().sum().sum())"
      ],
      "metadata": {
        "id": "AK7KmKQgZsIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final = df_flitered.drop_duplicates()\n",
        "df_final = df_final.replace([np.inf, -np.inf], 0)"
      ],
      "metadata": {
        "id": "GMY6RF8At2UG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_final.drop(columns=['target'])\n",
        "y = df_final['target']"
      ],
      "metadata": {
        "id": "hqMmtfyVueZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
        "print(len(X_train))\n",
        "print(len(X_test))"
      ],
      "metadata": {
        "id": "Q3RrHVpTulNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "lMl19lf-vxYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train_scaled,y_train)"
      ],
      "metadata": {
        "id": "d2kblcAQwIn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test_scaled)\n",
        "print(f\"Accuracy: {accuracy_score(y_test,y_pred)*100: .2f}%\")\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nDetailed Report:\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "qEkzMd9_wTpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names = X.columns\n",
        "coefficients = model.coef_[0]\n",
        "feature_importance = pd.DataFrame({'Feature': feature_names, 'Coefficient': abs(coefficients)})\n",
        "print(feature_importance)"
      ],
      "metadata": {
        "id": "YqF5UC0gwqJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_features = feature_importance.sort_values(by='Coefficient', ascending=False).head(20)\n",
        "print(top_features)"
      ],
      "metadata": {
        "id": "X0lk4-S4yAQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.parse\n",
        "import re\n",
        "import math\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "lq-J9aeVyRuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_entropy(s):\n",
        "  if not s:\n",
        "    return 0\n",
        "  counts = Counter(s)\n",
        "  length = len(s)\n",
        "\n",
        "  entropy = -sum((count/length) * math.log2(count/length) for count in counts.values())\n",
        "\n",
        "  return entropy\n",
        "\n",
        "\n",
        "def extractor(url):\n",
        "  features={}\n",
        "\n",
        "  if not url.startswith('http'):\n",
        "    url = 'http://' + url\n",
        "\n",
        "  parsed = urllib.parse.urlparse(url)\n",
        "\n",
        "  domain = parsed.netloc\n",
        "  path = parsed.path\n",
        "  query = parsed.query\n",
        "\n",
        "  try:\n",
        "    extension = path.split('.')[-1] if '.' in path else \"\"\n",
        "  except:\n",
        "    extension = \"\"\n",
        "\n",
        "  features['urlLen']=len(url)\n",
        "\n",
        "  features['domainlength']=len(domain)\n",
        "\n",
        "  features['pathLength']=len(path)\n",
        "\n",
        "  features['pathurlRatio']=len(path)/len(url) if len(url)>0 else 0\n",
        "\n",
        "  features['pathDomainRatio']=len(path)/len(domain) if len(domain)>0 else 0\n",
        "\n",
        "  features['host_letter_count']=len(re.findall(r'[a-zA-Z]', domain))\n",
        "\n",
        "  features['URL_DigitCount']=len(re.findall(r'[0-9]', url))\n",
        "\n",
        "  features['NumberofDotsinURL']= url.count('.')\n",
        "\n",
        "  features['delimeter_path']=len(re.findall(r'[^a-zA-Z0-9]', path))\n",
        "\n",
        "  if len(query)>0:\n",
        "    features['URLQueries_variable']=query.count('&')+1\n",
        "  else:\n",
        "    features['URLQueries_variable']=0\n",
        "\n",
        "  tokens=domain.split('.')\n",
        "\n",
        "  token_lengths= [len(t) for t in tokens if len(t)>0]\n",
        "\n",
        "  features['avgdomaintokenlen']=np.mean(token_lengths) if len(token_lengths)>0 else 0\n",
        "\n",
        "  if len(extension)>0:\n",
        "    digits_in_ext = len(re.findall(r'[0-9]',extension))\n",
        "    features['NumberRate_Extension'] = digits_in_ext / len(extension)\n",
        "  else:\n",
        "    features['NumberRate_Extension'] = 0\n",
        "\n",
        "  if '/' in path:\n",
        "    directory_part = path.rsplit('/',1)[0]+'/'\n",
        "    filename_part = path.rsplit('/',1)[1]\n",
        "  else:\n",
        "    directory_part=\"\"\n",
        "    filename_part=path\n",
        "\n",
        "  features['subDirLen']= len(directory_part)\n",
        "\n",
        "  features['Directory_DigitCount'] = len(re.findall(r'[0-9]', directory_part))\n",
        "\n",
        "  features['Directory_LetterCount'] = len(re.findall(r'[a-zA-Z]', directory_part))\n",
        "\n",
        "  features['Entropy_Filename'] = get_entropy(filename_part)\n",
        "\n",
        "  features['Query_LetterCount'] = len(re.findall(r'[a-zA-Z]', query))\n",
        "\n",
        "  if len(query) > 0:\n",
        "    digits_in_query = len(re.findall(r'[0-9]', query))\n",
        "    features['NumberRate_AfterPath'] = digits_in_query / len(query)\n",
        "  else:\n",
        "    features['NumberRate_AfterPath'] = 0\n",
        "\n",
        "  features['charcompvowels'] = len(re.findall(r'[aeiouAEIOU]', url))\n",
        "\n",
        "  features['SymbolCount_URL'] = len(re.findall(r'[^a-zA-Z0-9]', url))\n",
        "\n",
        "  return features"
      ],
      "metadata": {
        "id": "3EkV0pSZ3UnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_url = \"http://google.com/login/secure?user=123\"\n",
        "print(extractor(test_url))"
      ],
      "metadata": {
        "id": "QFkKYWGGGRbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_order = [\n",
        "    'urlLen', 'domainlength', 'pathLength', 'pathurlRatio', 'pathDomainRatio',\n",
        "    'host_letter_count', 'URL_DigitCount', 'NumberofDotsinURL', 'delimeter_path',\n",
        "    'URLQueries_variable', 'avgdomaintokenlen', 'NumberRate_Extension',\n",
        "    'subDirLen', 'Directory_DigitCount', 'Directory_LetterCount', 'Entropy_Filename',\n",
        "    'Query_LetterCount', 'NumberRate_AfterPath', 'charcompvowels', 'SymbolCount_URL'\n",
        "]"
      ],
      "metadata": {
        "id": "bsb_w6X4GWNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_selected = X[feature_order].copy()\n",
        "\n",
        "# X_train_new, X_test_new, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "9M_RineBG1lE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.metrics import f1_score, roc_auc_score\n",
        "# scaler_new = StandardScaler()\n",
        "# X_train_new_scaled = scaler_new.fit_transform(X_train_new)\n",
        "# X_test_new_scaled = scaler_new.transform(X_test_new)\n",
        "\n",
        "# model_new = LogisticRegression(max_iter=1000,class_weight='balanced')\n",
        "# model_new.fit(X_train_new_scaled, y_train)\n",
        "\n",
        "# y_pred_new = model_new.predict(X_test_new_scaled)\n",
        "\n",
        "# print(f\"New Model Accuracy: {model_new.score(X_test_new_scaled, y_test) * 100:.2f}%\")\n",
        "# print(\"\\nNewConfusion Matrix:\")\n",
        "# print(confusion_matrix(y_test, y_pred_new))\n",
        "# print(\"\\nNewDetailed Report:\")\n",
        "# print(classification_report(y_test, y_pred_new))\n",
        "\n",
        "# print(\"Train Accuracy:\", model_new.score(X_train_new_scaled, y_train))\n",
        "# print(\"Test Accuracy :\", model_new.score(X_test_new_scaled, y_test))\n",
        "# print(\"F1:\", f1_score(y_test, y_pred_new))\n",
        "# print(\"AUC:\", roc_auc_score(y_test, model_new.predict_proba(X_test_new_scaled)[:,1]))"
      ],
      "metadata": {
        "id": "SoFQvFQKH0rJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# def predict_url(url,model,scaler):\n",
        "#   features_dict = extractor(url)\n",
        "\n",
        "#   df_features = pd.DataFrame([features_dict])\n",
        "\n",
        "#   df_features = df_features.reindex(columns=feature_order, fill_value=0)\n",
        "\n",
        "#   scaled_features= scaler.transform(df_features)\n",
        "\n",
        "#   prediction = model.predict(scaled_features)[0]\n",
        "\n",
        "#   probability = model.predict_proba(scaled_features)[0][1]\n",
        "\n",
        "#   return prediction, probability"
      ],
      "metadata": {
        "id": "uOqJ7StJIDS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # --- TEST TIME ---\n",
        "# # Test 1: A legitimate site\n",
        "# safe_url = \"x.com/home\"\n",
        "# pred, prob = predict_url(safe_url, model_new, scaler_new) # Use your new model/scaler names\n",
        "\n",
        "# print(f\"URL: {safe_url}\")\n",
        "# print(f\"Prediction: {'PHISHING' if pred == 1 else 'SAFE'}\")\n",
        "# print(f\"Probability: {prob*100:.2f}% Phishing\\n\")\n"
      ],
      "metadata": {
        "id": "4JiaunyJKiNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfp = pd.read_csv('2.online-valid.csv')\n",
        "dfp.head()"
      ],
      "metadata": {
        "id": "36zF7TQXKk6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "phish = dfp.sample(n=5000,random_state=12).copy()\n",
        "phish = phish.reset_index(drop=True)\n",
        "phish.head()"
      ],
      "metadata": {
        "id": "dVmDwHUqZBsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfb = pd.read_csv('1.Benign_list_big_final.csv')\n",
        "dfb.columns = ['URLs']\n",
        "dfb.head()"
      ],
      "metadata": {
        "id": "2SWhIFkcZsct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ben = dfb.sample(n=5000,random_state=12).copy()\n",
        "ben = ben.reset_index(drop=True)\n",
        "ben.head()"
      ],
      "metadata": {
        "id": "YAX5bieiaEFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ben = ben[['URLs']]\n",
        "ben = ben.rename(columns={'URLs':'url'})\n",
        "\n",
        "phish = phish[['url']]\n"
      ],
      "metadata": {
        "id": "0PqLYFADabRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib.parse import urlparse,urlencode\n",
        "import ipaddress\n",
        "import re\n",
        "\n",
        "def getDomain(url):\n",
        "  domain = urlparse(url).netloc\n",
        "  if re.match(r\"^www.\",domain):\n",
        "\t       domain = domain.replace(\"www.\",\"\")\n",
        "  return domain\n",
        "\n",
        "def havingIP(url):\n",
        "  try:\n",
        "    ipaddress.ip_address(url)\n",
        "    ip = 1\n",
        "  except:\n",
        "    ip = 0\n",
        "  return ip\n",
        "\n",
        "def haveAtSign(url):\n",
        "  if \"@\" in url:\n",
        "    at = 1\n",
        "  else:\n",
        "    at = 0\n",
        "  return at\n",
        "\n",
        "def getLength(url):\n",
        "  if len(url) < 54:\n",
        "    length = 0\n",
        "  else:\n",
        "    length = 1\n",
        "  return length\n",
        "\n",
        "def getDepth(url):\n",
        "  s = urlparse(url).path.split('/')\n",
        "  depth = 0\n",
        "  for j in range(len(s)):\n",
        "    if len(s[j]) != 0:\n",
        "      depth = depth+1\n",
        "  return depth\n",
        "\n",
        "def redirection(url):\n",
        "  pos = url.rfind('//')\n",
        "  if pos > 6:\n",
        "    if pos > 7:\n",
        "      return 1\n",
        "    else:\n",
        "      return 0\n",
        "  else:\n",
        "    return 0\n",
        "def httpDomain(url):\n",
        "  domain = urlparse(url).netloc\n",
        "  if 'https' in domain:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "shortening_services = r\"bit\\.ly|goo\\.gl|shorte\\.st|go2l\\.ink|x\\.co|ow\\.ly|t\\.co|tinyurl|tr\\.im|is\\.gd|cli\\.gs|\" \\\n",
        "                      r\"yfrog\\.com|migre\\.me|ff\\.im|tiny\\.cc|url4\\.eu|twit\\.ac|su\\.pr|twurl\\.nl|snipurl\\.com|\" \\\n",
        "                      r\"short\\.to|BudURL\\.com|ping\\.fm|post\\.ly|Just\\.as|bkite\\.com|snipr\\.com|fic\\.kr|loopt\\.us|\" \\\n",
        "                      r\"doiop\\.com|short\\.ie|kl\\.am|wp\\.me|rubyurl\\.com|om\\.ly|to\\.ly|bit\\.do|t\\.co|lnkd\\.in|db\\.tt|\" \\\n",
        "                      r\"qr\\.ae|adf\\.ly|goo\\.gl|bitly\\.com|cur\\.lv|tinyurl\\.com|ow\\.ly|bit\\.ly|ity\\.im|q\\.gs|is\\.gd|\" \\\n",
        "                      r\"po\\.st|bc\\.vc|twitthis\\.com|u\\.to|j\\.mp|buzurl\\.com|cutt\\.us|u\\.bb|yourls\\.org|x\\.co|\" \\\n",
        "                      r\"prettylinkpro\\.com|scrnch\\.me|filoops\\.info|vzturl\\.com|qr\\.net|1url\\.com|tweez\\.me|v\\.gd|\" \\\n",
        "                      r\"tr\\.im|link\\.zip\\.net\"\n",
        "def tinyURL(url):\n",
        "    match=re.search(shortening_services,url)\n",
        "    if match:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def prefixSuffix(url):\n",
        "    if '-' in urlparse(url).netloc:\n",
        "        return 1            # phishing\n",
        "    else:\n",
        "        return 0            # legitimate\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SRnf4rZMmyFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-whois"
      ],
      "metadata": {
        "id": "Q9ULvGiVndxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "import whois\n",
        "import urllib\n",
        "import urllib.request\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "qqaPgeUJn3gN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def web_traffic(url):\n",
        "  try:\n",
        "    #Filling the whitespaces in the URL if any\n",
        "    url = urllib.parse.quote(url)\n",
        "    rank = BeautifulSoup(urllib.request.urlopen(\"http://data.alexa.com/data?cli=10&dat=s&url=\" + url).read(), \"xml\").find(\n",
        "        \"REACH\")['RANK']\n",
        "    rank = int(rank)\n",
        "  except TypeError:\n",
        "        return 1\n",
        "  if rank <100000:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "def domainAge(domain_name):\n",
        "  creation_date = domain_name.creation_date\n",
        "  expiration_date = domain_name.expiration_date\n",
        "  if (isinstance(creation_date,str) or isinstance(expiration_date,str)):\n",
        "    try:\n",
        "      creation_date = datetime.strptime(creation_date,'%Y-%m-%d')\n",
        "      expiration_date = datetime.strptime(expiration_date,\"%Y-%m-%d\")\n",
        "    except:\n",
        "      return 1\n",
        "  if ((expiration_date is None) or (creation_date is None)):\n",
        "      return 1\n",
        "  elif ((type(expiration_date) is list) or (type(creation_date) is list)):\n",
        "      return 1\n",
        "  else:\n",
        "    ageofdomain = abs((expiration_date - creation_date).days)\n",
        "    if ((ageofdomain/30) < 6):\n",
        "      age = 1\n",
        "    else:\n",
        "      age = 0\n",
        "  return age\n",
        "\n",
        "def domainEnd(domain_name):\n",
        "  expiration_date = domain_name.expiration_date\n",
        "  if isinstance(expiration_date,str):\n",
        "    try:\n",
        "      expiration_date = datetime.strptime(expiration_date,\"%Y-%m-%d\")\n",
        "    except:\n",
        "      return 1\n",
        "  if (expiration_date is None):\n",
        "      return 1\n",
        "  elif (type(expiration_date) is list):\n",
        "      return 1\n",
        "  else:\n",
        "    today = datetime.now()\n",
        "    end = abs((expiration_date - today).days)\n",
        "    if ((end/30) < 6):\n",
        "      end = 0\n",
        "    else:\n",
        "      end = 1\n",
        "  return end\n",
        "\n"
      ],
      "metadata": {
        "id": "NYMb_6mhn66J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def iframe(response):\n",
        "  if response == \"\":\n",
        "      return 1\n",
        "  else:\n",
        "      if re.findall(r\"[|]\", response.text):\n",
        "          return 0\n",
        "      else:\n",
        "          return 1\n",
        "\n",
        "def mouseOver(response):\n",
        "  if response == \"\" :\n",
        "    return 1\n",
        "  else:\n",
        "    if re.findall(\"\", response.text):\n",
        "      return 1\n",
        "    else:\n",
        "      return 0\n",
        "\n",
        "def rightClick(response):\n",
        "  if response == \"\":\n",
        "    return 1\n",
        "  else:\n",
        "    if re.findall(r\"event.button ?== ?2\", response.text):\n",
        "      return 0\n",
        "    else:\n",
        "      return 1\n",
        "\n",
        "def forwarding(response):\n",
        "  if response == \"\":\n",
        "    return 1\n",
        "  else:\n",
        "    if len(response.history) <= 2:\n",
        "      return 0\n",
        "    else:\n",
        "      return 1"
      ],
      "metadata": {
        "id": "o25hE8H5oJIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Extraction(url,label):\n",
        "\n",
        "  features = []\n",
        "  #Address bar based features (10)\n",
        "  features.append(getDomain(url))\n",
        "  features.append(havingIP(url))\n",
        "  features.append(haveAtSign(url))\n",
        "  features.append(getLength(url))\n",
        "  features.append(getDepth(url))\n",
        "  features.append(redirection(url))\n",
        "  features.append(httpDomain(url))\n",
        "  features.append(tinyURL(url))\n",
        "  features.append(prefixSuffix(url))\n",
        "\n",
        "  #Domain based features (4)\n",
        "  dns = 0\n",
        "  try:\n",
        "    domain_name = whois.whois(urlparse(url).netloc)\n",
        "  except:\n",
        "    dns = 1\n",
        "\n",
        "  features.append(dns)\n",
        "  features.append(web_traffic(url))\n",
        "  features.append(1 if dns == 1 else domainAge(domain_name))\n",
        "  features.append(1 if dns == 1 else domainEnd(domain_name))\n",
        "\n",
        "  # HTML & Javascript based features (4)\n",
        "  try:\n",
        "    response = requests.get(url)\n",
        "  except:\n",
        "    response = \"\"\n",
        "  features.append(iframe(response))\n",
        "  features.append(mouseOver(response))\n",
        "  features.append(rightClick(response))\n",
        "  features.append(forwarding(response))\n",
        "  features.append(label)\n",
        "\n",
        "  return features"
      ],
      "metadata": {
        "id": "g0zeBGPBoX8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "legi_features = []\n",
        "label = 0\n",
        "\n",
        "for i in range(0, 5000):\n",
        "  url = ben['URLs'][i]\n",
        "  legi_features.append(Extraction(url,label))\n"
      ],
      "metadata": {
        "id": "sJut_lWRr5FB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df = pd.DataFrame(rows)\n",
        "final_df.head()"
      ],
      "metadata": {
        "id": "mVskvzTScb1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_f = final_df.drop(columns=['target'])\n",
        "y_f = final_df['target']\n",
        "\n",
        "X_f_train, X_f_test, y_f_train, y_f_test = train_test_split(X_f,y_f,test_size=0.2,random_state=42)\n",
        "\n",
        "scaler_f = StandardScaler()\n",
        "X_f_train_scaled = scaler_f.fit_transform(X_f_train)\n",
        "X_f_test_scaled = scaler_f.transform(X_f_test)\n",
        "\n",
        "model_f = LogisticRegression(max_iter=1000)\n",
        "model_f.fit(X_f_train_scaled,y_f_train)"
      ],
      "metadata": {
        "id": "vM9WguN-chFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_f_pred = model_f.predict(X_f_test)\n",
        "print(f\"Accuracy: {accuracy_score(y_f_test,y_f_pred)*100: .2f}%\")\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_f_test, y_f_pred))\n",
        "print(\"\\nDetailed Report:\")\n",
        "print(classification_report(y_f_test, y_f_pred))"
      ],
      "metadata": {
        "id": "HuxvCRtvdImx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JWQ8rxCWdZ2G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}